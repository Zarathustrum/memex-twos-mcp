[build-system]
requires = ["setuptools>=68.0"]
build-backend = "setuptools.build_meta"

[project]
name = "memex-twos-mcp"
version = "0.1.0"
description = "MCP server for querying personal task data from Twos app exports"
readme = "README.md"
requires-python = ">=3.10"
dependencies = [
    "mcp[cli]>=1.0.0",
    "PyYAML>=6.0.1",
    "python-dateutil>=2.8.2",
    "sentence-transformers>=2.0.0",
    "sqlite-vec>=0.1.0",
    "numpy>=1.24.0",
    "rich>=13.0.0",
]

[project.optional-dependencies]
ner = [
    "spacy>=3.7.0,<4.0.0",
]
dev = [
    "pytest>=7.4.0",
    "black>=23.0.0",
    "flake8>=6.1.0",
    "mypy>=1.7.0",
    "types-PyYAML>=6.0.12.20250915",
]
# LLM Provider Dependencies (Phase 1: Anthropic API priority)
llm-anthropic = [
    "anthropic>=0.40.0",
]
llm-openai = [
    "openai>=1.0.0",
]
llm-gemini = [
    "google-generativeai>=0.8.0",
]
llm-local = [
    "httpx>=0.27.0",  # For Ollama and LM Studio HTTP APIs
]
llm-all = [
    "anthropic>=0.40.0",
    "openai>=1.0.0",
    "google-generativeai>=0.8.0",
    "httpx>=0.27.0",
]

[project.scripts]
memex-twos-mcp = "memex_twos_mcp.server:run"
